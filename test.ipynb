{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5\n",
    "import pickle\n",
    "from PIL import Image\n",
    "# train_X, train_Y = pickle5.load(open(\"./data/train/annot.pkl\", 'rb'))\n",
    "val_X, val_Y = pickle5.load(open(\"./data/val_annot.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"./colab_image_path.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from platform import python_version\n",
    "\n",
    "# Import pickle\n",
    "if int(''.join(python_version().split('.'))) < 380:\n",
    "    import pickle5 as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "def convert_label(origin_label:list):\n",
    "    label = np.array(origin_label)\n",
    "    label = np.round(label * 0.25)\n",
    "    idxs = np.lexsort((label[:,1], label[:,0]))\n",
    "\n",
    "    for i in range(len(idxs) - 1):\n",
    "        cur_idx, next_idx = idxs[i], idxs[i + 1]\n",
    "        if (label[cur_idx] == label[next_idx]).all():\n",
    "            return False, None\n",
    "\n",
    "    return True, label\n",
    "\n",
    "def get_transform(data_type=\"train\"):\n",
    "    means = [0.485, 0.456, 0.406]\n",
    "    stds = [0.229, 0.224, 0.225]\n",
    "    if data_type == \"train\":\n",
    "        transform = transforms.Compose([#transforms.RandomPerspective(distortion_scale=0.3),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        #transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.Normalize(means, stds),\n",
    "                                    ])\n",
    "    elif data_type == \"test\" or data_type == \"val\":\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Normalize(means, stds),\n",
    "                                    ])\n",
    "    return transform\n",
    "\n",
    "def get_train_val_dataset(data_root:str, annot_path:str):\n",
    "    images, labels = pickle.load(open(annot_path, 'rb'))\n",
    "    \n",
    "    valid_imgs = []\n",
    "    valid_labels = []\n",
    "    for img, label in zip(images, labels):\n",
    "        result = convert_label(label)\n",
    "        if result[0]:\n",
    "            valid_imgs.append(img)\n",
    "            valid_labels.append(result[1])\n",
    "\n",
    "    train_images, val_images, train_labels, val_labels = train_test_split(valid_imgs, valid_labels, train_size=0.8)\n",
    "    train_dataset = FaceSynthetics(data_root, train_images, train_labels, get_transform('train'))\n",
    "    val_dataset = FaceSynthetics(data_root, val_images, val_labels, get_transform('val'))\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "class FaceSynthetics(Dataset):\n",
    "    def __init__(self, data_root:str, images:list, labels:list, transform=None, heatmap_size=96) -> None:\n",
    "        super(FaceSynthetics, self).__init__()\n",
    "        self.data_root = data_root\n",
    "        self.images = images\n",
    "        self.labels= labels\n",
    "        self.transform = transform \n",
    "        \n",
    "        self.heatmap_size = heatmap_size\n",
    "\n",
    "    def generate_heatmap(self, label):\n",
    "        heatmap = np.zeros((self.heatmap_size, self.heatmap_size))\n",
    "        for (x, y) in label:\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx:int):\n",
    "        img_path = os.path.join(self.data_root, self.images[idx])\n",
    "        im = Image.open(img_path)\n",
    "        im = self.transform(im)\n",
    "        label = self.labels[idx]\n",
    "        return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = get_train_val_dataset(\"./data/train\", './data/val_annot.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fe8c35be263d59456f02e056f38c6d17b8ce95edb4a384e5646e7af7ca3397b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
